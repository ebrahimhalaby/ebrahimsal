{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ebrahimhalaby/ebrahimsal/blob/master/Arabic_Commands_BERT_Benchmark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stWXqgeq4YM6"
      },
      "source": [
        "# üß™ Arabic Commands BERT Benchmark (Colab-Ready)\n",
        "This notebook benchmarks multiple Arabic/Multilingual BERT models on your **commands dataset** (`text,intent`) with rigorous evaluation for research:\n",
        "- K-Fold CV over multiple random seeds.\n",
        "- Metrics: Accuracy, F1 (macro/micro), per-class PR/F1, confusion matrices.\n",
        "- Optional Arabic normalization ablation & class weighting.\n",
        "- Exports full results (CSVs, figures) to a ZIP and (optionally) Google Drive.\n",
        "\n",
        "> **Tip:** Start with a light configuration (fewer models/folds) to validate, then switch to the full configuration."
      ],
      "id": "stWXqgeq4YM6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFGmQU4-4YM7",
        "outputId": "4edef7e5-4f35-4bb8-974a-d7f7f87eb7c7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.1 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.12.0 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.5.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# ===============================\n",
        "# 0) Install dependencies\n",
        "# ===============================\n",
        "!pip install -q transformers==4.43.3 datasets==2.21.0 accelerate==0.33.0 \\\n",
        "evaluate==0.4.2 scikit-learn==1.5.2 pandas==2.2.2 numpy==1.26.4 \\\n",
        "onnx onnxruntime matplotlib==3.8.4 scipy==1.12.0\n"
      ],
      "id": "eFGmQU4-4YM7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJwtwQ0I4YM8",
        "outputId": "45262551-d2b0-4a60-8ee3-9280435ddaf1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# ===============================\n",
        "# 1) Mount Google Drive (optional)\n",
        "# ===============================\n",
        "USE_DRIVE = True   # <- set False if you don't want to use Drive\n",
        "\n",
        "if USE_DRIVE:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "DATA_FROM_DRIVE = True  # If True, the CSV is read from Drive path; else we'll use manual upload dialog.\n",
        "DRIVE_CSV_PATH = \"/content/drive/MyDrive/Colab Notebooks/arabic_game_commands_10k.csv\"  # <- change if using Drive\n"
      ],
      "id": "VJwtwQ0I4YM8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "p7o8pMwZ4YM8",
        "outputId": "a31979b5-c61f-4798-e65d-40d8a89343bc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CSV_PATH: /content/drive/MyDrive/Colab Notebooks/arabic_game_commands_10k.csv\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3474867547.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Using CSV_PATH:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCSV_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCSV_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"intent\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CSV must have 'text' and 'intent' columns\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "if DATA_FROM_DRIVE:\n",
        "    CSV_PATH = DRIVE_CSV_PATH\n",
        "else:\n",
        "    # Manual upload (dialog)\n",
        "    from google.colab import files\n",
        "    up = files.upload()  # choose your CSV\n",
        "    CSV_PATH = list(up.keys())[0]\n",
        "\n",
        "print(\"Using CSV_PATH:\", CSV_PATH)\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "assert {\"text\",\"intent\"}.issubset(df.columns), \"CSV must have 'text' and 'intent' columns\"\n",
        "df.head(5)\n"
      ],
      "id": "p7o8pMwZ4YM8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMI0R_6z4YM8"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ===============================\n",
        "# 3) Benchmark configuration\n",
        "# ===============================\n",
        "import os, re, json, numpy as np, matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "OUTPUT_ROOT = \"/content/bert_ar_commands_benchmark\"\n",
        "os.makedirs(OUTPUT_ROOT, exist_ok=True)\n",
        "\n",
        "# --- Toggle between LIGHT and FULL runs ---\n",
        "LIGHT_RUN = True  # True = faster sanity-check; False = full research run\n",
        "\n",
        "if LIGHT_RUN:\n",
        "    MODELS = [\n",
        "        \"aubmindlab/bert-base-arabertv2\",\n",
        "        \"UBC-NLP/MARBERT\",\n",
        "        \"xlm-roberta-base\",\n",
        "    ]\n",
        "    KFOLDS = 3\n",
        "    SEEDS = [42]\n",
        "    MAX_EPOCHS = 3\n",
        "else:\n",
        "    MODELS = [\n",
        "        \"aubmindlab/bert-base-arabertv2\",\n",
        "        \"asafaya/bert-base-arabic\",\n",
        "        \"UBC-NLP/ARBERT\",\n",
        "        \"UBC-NLP/MARBERT\",\n",
        "        \"bert-base-multilingual-cased\",\n",
        "        \"xlm-roberta-base\",\n",
        "    ]\n",
        "    KFOLDS = 5\n",
        "    SEEDS = [42, 77, 123]\n",
        "    MAX_EPOCHS = 6\n",
        "\n",
        "LR = 2e-5\n",
        "BATCH = 32\n",
        "PATIENCE = 2                     # Early stopping\n",
        "USE_CLASS_WEIGHTS = True\n",
        "USE_NORMALIZE = True\n",
        "\n",
        "print(\"Models:\", MODELS)\n",
        "print(\"KFOLDS:\", KFOLDS, \"| SEEDS:\", SEEDS, \"| EPOCHS:\", MAX_EPOCHS)\n"
      ],
      "id": "aMI0R_6z4YM8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbwZ5TBB4YM8"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ===============================\n",
        "# 4) Preprocess (Arabic normalization optional) + labels\n",
        "# ===============================\n",
        "import numpy as np\n",
        "df = df.dropna(subset=[\"text\",\"intent\"]).reset_index(drop=True)\n",
        "df[\"text\"] = df[\"text\"].astype(str).str.strip()\n",
        "df[\"intent\"] = df[\"intent\"].astype(str).str.strip()\n",
        "\n",
        "ARABIC_INDIC = \"Ÿ†Ÿ°Ÿ¢Ÿ£Ÿ§Ÿ•Ÿ¶ŸßŸ®Ÿ©\"\n",
        "WESTERN = \"0123456789\"\n",
        "DIGIT_MAP = str.maketrans(ARABIC_INDIC, WESTERN)\n",
        "\n",
        "def normalize_ar(text: str) -> str:\n",
        "    t = text.strip()\n",
        "    t = re.sub(r\"[\\u0640]+\", \"\", t)             # Tatweel\n",
        "    t = t.translate(DIGIT_MAP)                  # Ÿ°Ÿ¢Ÿ£ -> 123\n",
        "    t = re.sub(r\"[ŸÄ]+\", \"\", t)                  # Madd\n",
        "    t = re.sub(r\"\\s+\", \" \", t)                  # Spaces\n",
        "    t = re.sub(\"[ÿ•ÿ£ÿ¢ÿß]\", \"ÿß\", t)\n",
        "    t = re.sub(\"Ÿâ\", \"Ÿä\", t)\n",
        "    t = re.sub(\"ÿ§\", \"Ÿà\", t)\n",
        "    t = re.sub(\"ÿ¶\", \"Ÿä\", t)\n",
        "    t = t.replace(\"ÿ©\", \"Ÿá\")\n",
        "    t = re.sub(r\"[\\u0610-\\u061A\\u064B-\\u065F\\u0670\\u06D6-\\u06ED]\", \"\", t)  # Diacritics\n",
        "    t = re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\", t)       # Limit long char repeats\n",
        "    return t\n",
        "\n",
        "df[\"text_norm\"] = df[\"text\"].map(normalize_ar) if USE_NORMALIZE else df[\"text\"]\n",
        "\n",
        "labels = sorted(df[\"intent\"].unique().tolist())\n",
        "label2id = {l:i for i,l in enumerate(labels)}\n",
        "id2label = {i:l for l,i in label2id.items()}\n",
        "df[\"label\"] = df[\"intent\"].map(label2id)\n",
        "\n",
        "print(\"Num samples:\", len(df), \"| Num classes:\", len(labels))\n",
        "print(\"Classes:\", labels)\n"
      ],
      "id": "tbwZ5TBB4YM8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOSbPvGa4YM8"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ===============================\n",
        "# 5) Training & Cross-Validation\n",
        "# ===============================\n",
        "import warnings, math\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import evaluate\n",
        "\n",
        "from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n",
        "                          DataCollatorWithPadding, TrainingArguments, Trainer,\n",
        "                          EarlyStoppingCallback, set_seed)\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics_builder():\n",
        "    def compute_metrics(eval_pred):\n",
        "        logits, labels_np = eval_pred\n",
        "        preds = np.argmax(logits, axis=-1)\n",
        "        acc = accuracy.compute(predictions=preds, references=labels_np)[\"accuracy\"]\n",
        "        f1_macro = f1_metric.compute(predictions=preds, references=labels_np, average=\"macro\")[\"f1\"]\n",
        "        f1_micro = f1_metric.compute(predictions=preds, references=labels_np, average=\"micro\")[\"f1\"]\n",
        "        return {\"accuracy\": acc, \"f1_macro\": f1_macro, \"f1_micro\": f1_micro}\n",
        "    return compute_metrics\n",
        "\n",
        "USE_FP16 = torch.cuda.is_available()\n",
        "\n",
        "def train_eval_one_fold(model_name, seed, tr_idx, va_idx, outdir):\n",
        "    set_seed(seed)\n",
        "    tok = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    # HF datasets\n",
        "    train_ds = Dataset.from_pandas(df.iloc[tr_idx][[\"text_norm\",\"label\"]].rename(columns={\"text_norm\":\"text\"}))\n",
        "    val_ds   = Dataset.from_pandas(df.iloc[va_idx][[\"text_norm\",\"label\"]].rename(columns={\"text_norm\":\"text\"}))\n",
        "\n",
        "    def tok_fn(batch): return tok(batch[\"text\"], truncation=True)\n",
        "    train_ds = train_ds.map(tok_fn, batched=True, remove_columns=[\"text\"])\n",
        "    val_ds   = val_ds.map(tok_fn, batched=True, remove_columns=[\"text\"])\n",
        "    data_collator = DataCollatorWithPadding(tokenizer=tok)\n",
        "\n",
        "    loss_weights = None\n",
        "    if USE_CLASS_WEIGHTS:\n",
        "        y = df.iloc[tr_idx][\"label\"].values\n",
        "        cw = compute_class_weight(\"balanced\", classes=np.arange(len(labels)), y=y)\n",
        "        loss_weights = torch.tensor(cw, dtype=torch.float)\n",
        "\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_name, num_labels=len(labels), id2label=id2label, label2id=label2id\n",
        "    )\n",
        "\n",
        "    def compute_loss(model, inputs, return_outputs=False):\n",
        "        labels_t = inputs.get(\"labels\")\n",
        "        outputs = model(**{k:v for k,v in inputs.items() if k!=\"labels\"})\n",
        "        logits = outputs.logits\n",
        "        loss_fct = torch.nn.CrossEntropyLoss(weight=(loss_weights.to(logits.device) if loss_weights is not None else None))\n",
        "        loss = loss_fct(logits, labels_t)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "    args = TrainingArguments(\n",
        "        output_dir=outdir,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1_macro\",\n",
        "        greater_is_better=True,\n",
        "        learning_rate=LR,\n",
        "        per_device_train_batch_size=BATCH,\n",
        "        per_device_eval_batch_size=BATCH,\n",
        "        num_train_epochs=MAX_EPOCHS,\n",
        "        warmup_ratio=0.1,\n",
        "        weight_decay=0.01,\n",
        "        fp16=USE_FP16,\n",
        "        logging_steps=50,\n",
        "        report_to=\"none\",\n",
        "        seed=seed\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model, args=args,\n",
        "        train_dataset=train_ds, eval_dataset=val_ds,\n",
        "        tokenizer=tok, data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics_builder(),\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=PATIENCE)]\n",
        "    )\n",
        "    trainer.compute_loss = compute_loss\n",
        "\n",
        "    trainer.train()\n",
        "    out = trainer.predict(val_ds)\n",
        "    preds = np.argmax(out.predictions, axis=-1)\n",
        "    y_true = np.array(val_ds[\"label\"])\n",
        "\n",
        "    acc = accuracy_score(y_true, preds)\n",
        "    p, r, f1s, _ = precision_recall_fscore_support(y_true, preds, labels=np.arange(len(labels)))\n",
        "    f1_macro = f1s.mean()\n",
        "    f1_micro = precision_recall_fscore_support(y_true, preds, average=\"micro\")[2]\n",
        "    cm = confusion_matrix(y_true, preds, labels=np.arange(len(labels)))\n",
        "\n",
        "    # Save confusion matrix fig\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.figure()\n",
        "    plt.imshow(cm, interpolation='nearest')\n",
        "    plt.title(f\"CM {model_name} s{seed}\")\n",
        "    plt.colorbar()\n",
        "    plt.xticks(range(len(labels)), labels, rotation=45, ha=\"right\")\n",
        "    plt.yticks(range(len(labels)), labels)\n",
        "    plt.tight_layout()\n",
        "    cm_path = os.path.join(outdir, \"confusion_matrix.png\")\n",
        "    plt.savefig(cm_path); plt.close()\n",
        "\n",
        "    # Save per-class report\n",
        "    per_class = {labels[i]: {\"precision\": float(p[i]), \"recall\": float(r[i]), \"f1\": float(f1s[i])} for i in range(len(labels))}\n",
        "    with open(os.path.join(outdir, \"per_class.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(per_class, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    return {\n",
        "        \"metrics\": {\"accuracy\": float(acc), \"f1_macro\": float(f1_macro), \"f1_micro\": float(f1_micro)},\n",
        "        \"val_true\": y_true.tolist(),\n",
        "        \"val_pred\": preds.tolist()\n",
        "    }\n",
        "\n",
        "all_rows = []\n",
        "store_preds = {}\n",
        "\n",
        "from datetime import datetime\n",
        "RUN_TAG = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "for model_name in MODELS:\n",
        "    for seed in SEEDS:\n",
        "        skf = StratifiedKFold(n_splits=KFOLDS, shuffle=True, random_state=seed)\n",
        "        for fold, (tr_idx, va_idx) in enumerate(skf.split(df[\"text_norm\"], df[\"label\"])):\n",
        "            outdir = f\"{OUTPUT_ROOT}/{RUN_TAG}/{model_name.replace('/','_')}/seed{seed}_fold{fold}\"\n",
        "            os.makedirs(outdir, exist_ok=True)\n",
        "            print(f\"\\n=== {model_name} | seed={seed} | fold={fold+1}/{KFOLDS} ===\")\n",
        "            res = train_eval_one_fold(model_name, seed, tr_idx, va_idx, outdir)\n",
        "            row = {\"model\": model_name, \"seed\": seed, \"fold\": fold}\n",
        "            row.update(res[\"metrics\"])\n",
        "            all_rows.append(row)\n",
        "            store_preds[f\"{model_name}|seed{seed}|fold{fold}\"] = res\n",
        "\n",
        "import pandas as pd\n",
        "cv_df = pd.DataFrame(all_rows)\n",
        "cv_df.to_csv(f\"{OUTPUT_ROOT}/{RUN_TAG}/cv_results.csv\", index=False)\n",
        "summary = cv_df.groupby(\"model\")[[\"accuracy\",\"f1_macro\",\"f1_micro\"]].agg([\"mean\",\"std\"]).reset_index()\n",
        "summary_path = f\"{OUTPUT_ROOT}/{RUN_TAG}/cv_summary.csv\"\n",
        "summary.to_csv(summary_path, index=False)\n",
        "summary\n"
      ],
      "id": "fOSbPvGa4YM8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FpofrJR4YM9"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ===============================\n",
        "# 6) Pairwise bootstrap significance (ŒîF1_macro) between models\n",
        "# ===============================\n",
        "import numpy as np, pandas as pd\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "cv_df = pd.read_csv(f\"{OUTPUT_ROOT}/{RUN_TAG}/cv_results.csv\")\n",
        "models_unique = cv_df[\"model\"].unique().tolist()\n",
        "\n",
        "def paired_bootstrap_f1(y_true, pred_a, pred_b, B=2000):\n",
        "    y_true = np.array(y_true); pa = np.array(pred_a); pb = np.array(pred_b)\n",
        "    n = len(y_true)\n",
        "    rng = np.random.default_rng(2024)\n",
        "    def f1_macro(y, p):\n",
        "        _, _, f1s, _ = precision_recall_fscore_support(y, p, labels=np.unique(y))\n",
        "        return float(np.mean(f1s))\n",
        "    diffs = []\n",
        "    for _ in range(B):\n",
        "        idx = rng.integers(0, n, n)\n",
        "        diffs.append(f1_macro(y_true[idx], pa[idx]) - f1_macro(y_true[idx], pb[idx]))\n",
        "    diffs = np.array(diffs)\n",
        "    lo, hi = np.quantile(diffs, [0.025, 0.975])\n",
        "    return float(diffs.mean()), float(lo), float(hi)\n",
        "\n",
        "stats_rows = []\n",
        "for i in range(len(models_unique)):\n",
        "    for j in range(i+1, len(models_unique)):\n",
        "        A, Bm = models_unique[i], models_unique[j]\n",
        "        diffs = []\n",
        "        for seed in SEEDS:\n",
        "            for fold in range(KFOLDS):\n",
        "                keyA = f\"{A}|seed{seed}|fold{fold}\"\n",
        "                keyB = f\"{Bm}|seed{seed}|fold{fold}\"\n",
        "                if keyA in store_preds and keyB in store_preds:\n",
        "                    y_true = store_preds[keyA][\"val_true\"]\n",
        "                    pa = store_preds[keyA][\"val_pred\"]\n",
        "                    pb = store_preds[keyB][\"val_pred\"]\n",
        "                    mean_d, lo, hi = paired_bootstrap_f1(y_true, pa, pb, B=1500 if LIGHT_RUN else 3000)\n",
        "                    diffs.append((mean_d, lo, hi))\n",
        "        if diffs:\n",
        "            mean_over = float(np.mean([d[0] for d in diffs]))\n",
        "            lo_over   = float(np.mean([d[1] for d in diffs]))\n",
        "            hi_over   = float(np.mean([d[2] for d in diffs]))\n",
        "            stats_rows.append({\"A\":A, \"B\":Bm, \"ŒîF1_macro_mean\": mean_over, \"CI_low\": lo_over, \"CI_high\": hi_over})\n",
        "\n",
        "stats_df = pd.DataFrame(stats_rows)\n",
        "stats_df.to_csv(f\"{OUTPUT_ROOT}/{RUN_TAG}/pairwise_bootstrap_macroF1.csv\", index=False)\n",
        "stats_df\n"
      ],
      "id": "4FpofrJR4YM9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stXqv7sD4YM9"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ===============================\n",
        "# 7) Retrain best model on all data & export (Torch/ONNX/int8)\n",
        "# ===============================\n",
        "best_model = summary.sort_values((\"f1_macro\",\"mean\"), ascending=False)[\"model\"].iloc[0]\n",
        "best_model\n"
      ],
      "id": "stXqv7sD4YM9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvcAdz9B4YM9"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os, json, numpy as np, torch\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n",
        "                          DataCollatorWithPadding, TrainingArguments, Trainer,\n",
        "                          EarlyStoppingCallback)\n",
        "\n",
        "final_dir = f\"{OUTPUT_ROOT}/{RUN_TAG}/final_{best_model.replace('/','_')}\"\n",
        "os.makedirs(final_dir, exist_ok=True)\n",
        "\n",
        "tok = AutoTokenizer.from_pretrained(best_model)\n",
        "\n",
        "# small internal split for early stopping\n",
        "skf = StratifiedKFold(n_splits=8, shuffle=True, random_state=999)\n",
        "tr_idx, va_idx = list(skf.split(df[\"text_norm\"], df[\"label\"]))[0]\n",
        "\n",
        "train_ds = Dataset.from_pandas(df.iloc[tr_idx][[\"text_norm\",\"label\"]].rename(columns={\"text_norm\":\"text\"}))\n",
        "val_ds   = Dataset.from_pandas(df.iloc[va_idx][[\"text_norm\",\"label\"]].rename(columns={\"text_norm\":\"text\"}))\n",
        "\n",
        "def tok_fn(b): return tok(b[\"text\"], truncation=True)\n",
        "train_ds = train_ds.map(tok_fn, batched=True, remove_columns=[\"text\"])\n",
        "val_ds   = val_ds.map(tok_fn, batched=True, remove_columns=[\"text\"])\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tok)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    best_model, num_labels=len(labels), id2label=id2label, label2id=label2id\n",
        ")\n",
        "\n",
        "if USE_CLASS_WEIGHTS:\n",
        "    y = df.iloc[tr_idx][\"label\"].values\n",
        "    cw = compute_class_weight(\"balanced\", classes=np.arange(len(labels)), y=y)\n",
        "    loss_weights = torch.tensor(cw, dtype=torch.float)\n",
        "else:\n",
        "    loss_weights = None\n",
        "\n",
        "def compute_loss(model, inputs, return_outputs=False):\n",
        "    labels_t = inputs.get(\"labels\")\n",
        "    outputs = model(**{k:v for k,v in inputs.items() if k!=\"labels\"})\n",
        "    logits = outputs.logits\n",
        "    loss_fct = torch.nn.CrossEntropyLoss(weight=(loss_weights.to(logits.device) if loss_weights is not None else None))\n",
        "    loss = loss_fct(logits, labels_t)\n",
        "    return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=final_dir,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1_macro\",\n",
        "    greater_is_better=True,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=6,\n",
        "    warmup_ratio=0.1,\n",
        "    weight_decay=0.01,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    logging_steps=50,\n",
        "    report_to=\"none\",\n",
        "    seed=2025\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model, args=args,\n",
        "    train_dataset=train_ds, eval_dataset=val_ds,\n",
        "    tokenizer=tok, data_collator=data_collator,\n",
        "    compute_metrics=None,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        ")\n",
        "trainer.compute_loss = compute_loss\n",
        "trainer.train()\n",
        "\n",
        "# Save (Torch)\n",
        "trainer.save_model(final_dir)\n",
        "tok.save_pretrained(final_dir)\n",
        "with open(os.path.join(final_dir, \"label_map.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump({\"labels\": labels, \"label2id\": {k:int(v) for k,v in label2id.items()},\n",
        "               \"id2label\": {int(k):v for k,v in id2label.items()}}, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "# Export ONNX\n",
        "dummy = tok(\"ÿßÿÆÿ™ÿ®ÿßÿ±\", return_tensors=\"pt\")\n",
        "model.to(\"cpu\").eval()\n",
        "onnx_path = os.path.join(final_dir, \"model.onnx\")\n",
        "torch.onnx.export(\n",
        "    model,\n",
        "    (dummy[\"input_ids\"], dummy[\"attention_mask\"]),\n",
        "    onnx_path,\n",
        "    input_names=[\"input_ids\",\"attention_mask\"],\n",
        "    output_names=[\"logits\"],\n",
        "    dynamic_axes={\"input_ids\":{0:\"batch\",1:\"seq\"}, \"attention_mask\":{0:\"batch\",1:\"seq\"}, \"logits\":{0:\"batch\"}},\n",
        "    opset_version=17\n",
        ")\n",
        "\n",
        "# Optional quantization\n",
        "try:\n",
        "    from onnxruntime.quantization import quantize_dynamic, QuantType\n",
        "    quantize_dynamic(onnx_path, os.path.join(final_dir, \"model.int8.onnx\"), weight_type=QuantType.QInt8)\n",
        "except Exception as e:\n",
        "    print(\"Quantization skipped:\", e)\n",
        "\n",
        "final_dir\n"
      ],
      "id": "yvcAdz9B4YM9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEc2dWla4YM-"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ===============================\n",
        "# 8) Export all results as ZIP (and copy to Drive)\n",
        "# ===============================\n",
        "import shutil, os\n",
        "\n",
        "ZIP_PATH = f\"/content/Arabic_Commands_BERT_Results_{RUN_TAG}.zip\"\n",
        "shutil.make_archive(base_name=ZIP_PATH.replace(\".zip\",\"\"), format=\"zip\", root_dir=f\"{OUTPUT_ROOT}/{RUN_TAG}\")\n",
        "print(\"ZIP created at:\", ZIP_PATH)\n",
        "\n",
        "# Copy to Drive\n",
        "if USE_DRIVE:\n",
        "    DRIVE_OUT = f\"/content/drive/MyDrive/Arabic_Commands_BERT_Results_{RUN_TAG}.zip\"\n",
        "    shutil.copyfile(ZIP_PATH, DRIVE_OUT)\n",
        "    print(\"Copied ZIP to Drive:\", DRIVE_OUT)\n"
      ],
      "id": "OEc2dWla4YM-"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qb7rCj64YM-"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ===============================\n",
        "# 9) Quick inference function (loads final best model)\n",
        "# ===============================\n",
        "import json, numpy as np, torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "def normalize_ar(text: str) -> str:\n",
        "    t = text.strip()\n",
        "    t = re.sub(r\"[\\u0640]+\", \"\", t)\n",
        "    t = t.translate(str.maketrans(\"Ÿ†Ÿ°Ÿ¢Ÿ£Ÿ§Ÿ•Ÿ¶ŸßŸ®Ÿ©\",\"0123456789\"))\n",
        "    t = re.sub(r\"[ŸÄ]+\", \"\", t)\n",
        "    t = re.sub(r\"\\s+\", \" \", t)\n",
        "    t = re.sub(\"[ÿ•ÿ£ÿ¢ÿß]\", \"ÿß\", t)\n",
        "    t = re.sub(\"Ÿâ\", \"Ÿä\", t)\n",
        "    t = re.sub(\"ÿ§\", \"Ÿà\", t)\n",
        "    t = re.sub(\"ÿ¶\", \"Ÿä\", t)\n",
        "    t = t.replace(\"ÿ©\", \"Ÿá\")\n",
        "    t = re.sub(r\"[\\u0610-\\u061A\\u064B-\\u065F\\u0670\\u06D6-\\u06ED]\", \"\", t)\n",
        "    t = re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\", t)\n",
        "    return t\n",
        "\n",
        "best_dir = final_dir  # from previous cell\n",
        "tok = AutoTokenizer.from_pretrained(best_dir)\n",
        "mdl = AutoModelForSequenceClassification.from_pretrained(best_dir)\n",
        "id2label = mdl.config.id2label\n",
        "\n",
        "def predict(text, threshold=0.55):\n",
        "    t = normalize_ar(text)\n",
        "    enc = tok(t, return_tensors=\"pt\", truncation=True)\n",
        "    with torch.no_grad():\n",
        "        logits = mdl(**enc).logits\n",
        "        probs = torch.softmax(logits, dim=-1).numpy().squeeze()\n",
        "    idx = int(np.argmax(probs))\n",
        "    conf = float(probs[idx])\n",
        "    label = id2label[idx] if conf >= threshold else \"UNKNOWN\"\n",
        "    return {\"text\": text, \"norm\": t, \"label\": label, \"confidence\": round(conf, 4)}\n",
        "\n",
        "print(predict(\"ŸäŸÑÿß ÿßÿ≥ÿ™ÿØÿ±Ÿ°Ÿ®Ÿ† ŸÑŸÑŸäŸÖŸäŸÜ\"))\n",
        "print(predict(\"ŸÑŸà ÿ≥ŸÖÿ≠ÿ™ ŸÇŸÅ ÿ®ÿ≥ÿ±ÿπÿ©\"))\n",
        "print(predict(\"ÿßÿπŸÖŸÑ ÿ¥Ÿä ÿ∫ÿ±Ÿäÿ® ŸÖÿß ÿ®ÿπÿ±ŸÅ\"))\n"
      ],
      "id": "3qb7rCj64YM-"
    }
  ]
}